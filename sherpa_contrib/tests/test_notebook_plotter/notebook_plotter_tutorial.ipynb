{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **notebook_plotter() by D. Principe (principe@space.mit.edu) -- MIT SDS Feb 2024**\n",
    "\n",
    "#### This jupyter notebook is designed to demonstrate the potential for using Jupyter Widgets (ipywidgets) to interactively view sherpa models and data. This tool must be run with jupyter notebooks, sherpa and the ipywidgets package. This notebook includes a function 'notebook_plotter()' that will create an interactive plot window allowing users to modify model parameters in real-time to visually inspect how an unconvolved model would look convolved with the instrument associated with the sherpa dataset. This function has current features which include:\n",
    "\n",
    "(a) inspecting sherpa or xspec models over a grid with a user-supplied spectral resolution (unlike plot_source() where the resolution is fixed)\n",
    "\n",
    "(b) interactively plot both the unconvolved model and the model convovled with the loaded instrument responses. This feature can be useful for proposal planning if a user want's to fake data to know if a certain spectral feature will be observable with Chandra (or any other instrument loaded in the sherpa session). \n",
    "\n",
    "(c) interactively plot a loaded dataset and the model convolved with responses. Users can alter parameters to see how that could affect their spectral fitting. This is particularly useful for identifying degeneracies between model parameters.\n",
    "\n",
    "(d) You can create multiple interactive plots using multiple notebook cells and they remain independent (more or less).\n",
    "\n",
    "#### This prototye can also serve as an educational tool to be used in CIAO workshops for users new to X-ray astronomy. This tool is not necessarily dependent on Chandra data. If other telescope spectra (e.g., XMM-Newton, NuSTAR) can be loaded into sherpa then it should work with this.\n",
    "\n",
    "#### Current restrictions of the tool are:\n",
    "\n",
    "- You can not plot more than one model type or dataset on the same interactive plot.\n",
    "\n",
    "- the widget slider relies on a reasonable range of parameter values. If some model parameters have a minimum of 0 and maximum of 1E23 (for example) then a slider is not going to function very well. Users will have to set the min/max values of parameters (eg., a1.nH.max = 100) with physically-reasonable values before calling the interactive model. \n",
    "\n",
    "#### Features I would like to add in the future:\n",
    "\n",
    "(a) use this tool to set a model and press a widget button to directly simulate a spectrum with fake_pha() for proposal planning purposes.\n",
    "\n",
    "(b) allow users to save a screenshot of what is displayed as a pdf, png, etc.\n",
    "\n",
    "(c) work with multiple datasets that also include multiple responses (e.g., HETGs HEG+MEG orders)\n",
    "\n",
    "(d) change models interactively by clicking on one from a dropdown box in the plotting window\n",
    "\n",
    "(e) allow users to set the model with the widget sliders and then re-fit the data using a 'FIT' button in the plotting window. \n",
    "\n",
    "(f) when a user saves a best fit model, add a button to the plotter which will set all values to the best fit model. Alternatively, the tool could read saved models and load them.\n",
    "\n",
    "\n",
    "#### More information about Jupyter Widgets (ipywidgets) can be found here:\n",
    "\n",
    "https://ipywidgets.readthedocs.io/en/latest/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **USAGE INSTRUCTIONS**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool requires the ipywidget module which can be installed using either the pip ('pip install ipywidgets') or the conda install method ('conda install ipywidgets'). Once CIAO is initialized you should be able to run this notebook by typing \"jupyter notebook FILENAME\" where FILENAME is the location of this file.\n",
    "\n",
    "This notebook includes the following three examples:\n",
    "\n",
    "- EXAMPLE 1: Navigating the plotter and examining an unconvolved model\n",
    "\n",
    "- EXAMPLE 2: Loading and fitting a spectrum while visually inspecting how the model parameters may influence the overall fit\n",
    "\n",
    "- EXAMPLE 3 - Simulating a spectrum for a proposal with help from notebook_plotter()\n",
    "\n",
    "The 'notebook_plotter()' function is described more below and only technically requires a model to be defined but other features also require a response (so it can plot the convolved model and counts data). \n",
    "\n",
    "If for some reason the notebook_plotter function does not properly plot, please make sure you 'trust' the jupyter notebook file when opening it in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_plotter import notebook_plotter\n",
    "\n",
    "from sherpa.astro.ui import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can use the help(notebook_plotter) to learn more about the function and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(notebook_plotter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook includes several examples of how to use notebook_plotter(). As such, it's a good idea to run sherpa's clean() function in case you want to re-run this example after running later examples in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXAMPLE 1: Navigating the plotter and examining an unconvolved model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use sherpa to generate a spectral model and plot it with notebook_plotter().The model here is an absorbed, one-temperature thermal plasma typical of coronal emission from a bright, young pre-main sequence star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = xstbabs.ma1 * (xsapec.p1)\n",
    "test_model #we can print the model parameters out to the notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking over the model parameters (above), we'll want to constrain what will be plotted with more physically-appropriate limits. For example, xspec xstbabs model has a maxmimum nH value of 1,000,000 (1E28 atoms/cm2) and that value is not relevant for nearby young stars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma1.nH.min = 0.01\n",
    "ma1.nH.max = 40\n",
    "p1.redshift.min = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's open this model in the notebook_plotter() by simply calling it as a variable to the notebook_plotter function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_plotter(test_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Here you can see the basic notebook interface with the model parameters on the left and the plotting options on the right. Each parameter of the tool is controlled using an ipywidget and there are several different ipywidgets to interact with. You can activate 'sliding widgets' in one of three ways: (a) by clicking on the blue circle and dragging the parameter left or right, (b) clicking on the line where you want the slider to go, or (c) clicking the value to the right of the widget and typing in a new value. 'Float text' widgets are boxes with a value displayed. You can click in the box and enter your own value or you can hover to the right of the box and click up or down to change the parameter by one widget unit. The 'dropdown' widgets can be selected by clicking them and picking an option from the dropdown menu. Note that you can interactively change the size of the plotting window using the figsize_x and y parameter sliders.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *This plotting tool can also be opened in a specific state by calling the function with the parameters listed in the plotting options using the same syntax. If the parameter requires a string and the wrong syntax is used then the plot warns you that the tool's default value for that parameter will instead be used.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_plotter(test_model, log_axis = 'ylog', xlim_low = 0.3, xlim_high =10, figsize_y = 3, plot_type = 'model_unconvolved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Something to note is that the test_model paramater values **WILL** be updated in your sherpa session with the widget values selected in the interactive plot after running notebook_plotter(). This can be useful when trying to fit models to data but dangerous if you are not aware that model values are being updated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Here we can see that the sherpa model values have been updated to the same as those shown in the interactive plot.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXAMPLE 2: Loading and fitting a spectrum while visually inspecting how the model parameters may influence the overall fit.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This example is meant to show how to use notebook_plotter() with a real dataset. However, that would require downloading a dataset and extracting a spectrum which is beyond the scope of this guide. Instead, we will simulate a spectrum and save it as a dataset.  \n",
    "\n",
    "#### Users who wish to learn more are about extracting spectra for real datasets are encouraged to see the following CIAO thread (https://cxc.cfa.harvard.edu/ciao/threads/pointlike/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to simulate a spectrum we will first need to download Chandra ARF and RMF responses for our instrument of choice (ACIS-S). For this example, we will use recent responses generated for proposal planning purposes only can be found here (https://cxc.cfa.harvard.edu/caldb/prop_plan/imaging/). Please note that these responses are only meant to be used for simulating spectra and should not be used to analyze real Chandra observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "#download the ACIS-S ARF\n",
    "url_arf = ('https://cxc.cfa.harvard.edu/caldb/prop_plan/imaging/CY26/aciss_aimpt_cy26.arf')\n",
    "filename_arf = 'aciss_aimpt_cy26.arf'\n",
    "urlretrieve(url_arf, filename_arf)\n",
    "\n",
    "#download the ACIS-S RMF\n",
    "url_rmf = ('https://cxc.cfa.harvard.edu/caldb/prop_plan/imaging/CY26/aciss_aimpt_cy26.rmf')\n",
    "filename_rmf = 'aciss_aimpt_cy26.rmf'\n",
    "urlretrieve(url_rmf, filename_rmf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can define a model, set some parameter values and simulate a spectrum using fake_pha(). The model here is an absorbed, one-temperature thermal plasma typical of coronal emission from a bright, young pre-main sequence star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean()\n",
    "\n",
    "#lets define a model and set it as the source_model\n",
    "model_for_simulation = xstbabs.asim * (xsvapec.psim)\n",
    "set_source(model_for_simulation)\n",
    "\n",
    "#here we can set some model parameters and the simulation exposure time\n",
    "asim.nH = 0.1 \n",
    "psim.kT = 2 #keV\n",
    "psim.norm  = 1E-3\n",
    "\n",
    "simulation_exposure = 50E3 #ks\n",
    "\n",
    "#simulate the spectrum and save it as a file in order to replicate the experience of loading in a real sources spectrum.\n",
    "fake_pha(1, arf = filename_arf, rmf = filename_rmf, exposure = simulation_exposure)\n",
    "save_pha(1,'simulated_spectrum.pi', clobber = 'yes')\n",
    "\n",
    "model_for_simulation #lets print the model parameters to the screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have a (simualted) dataset, lets load it in to sherpa as though it is a real source's spectrum. Note, the ARF and RMF should be automatically identified with the load_pha() command as those were the responses used to generate the spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean() #here we run clean() so the simulated dataset and source model are removed from the sherpa session.\n",
    "\n",
    "pha_file = 'simulated_spectrum.pi'\n",
    "\n",
    "load_pha(pha_file)\n",
    "\n",
    "plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can group the spectrum and plot it using the plot_data() sherpa command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the spectrum and ignore everthing but 0.5-8.0 keV counts\n",
    "group_counts(1,10)\n",
    "notice()\n",
    "ignore(0,0.5)\n",
    "ignore(8,)\n",
    "\n",
    "#replot the grouped spectra with log yscale\n",
    "plot_data()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have some data loaded, we will want to define a spectral model before we fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets define a model and set it as the source_model\n",
    "test_model_2 = xstbabs.ma2 * (xsvapec.p2)\n",
    "set_source(test_model_2)\n",
    "test_model_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we are using data simulated with a model, we happen to know the exact model parameter values. This would not be the case for a real observation. That being said, we can still use notebook_plotter() to set some reasonable parameter values before running fit(). Try modifying the parameters ma2.nH, p2.kT and p2.norm until the model looks more like the dataset. Instead of using the sliders, you can also click the values to the right of the sliders and set them with keyboard input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma2.nH.max = 30 #lets set nH to a physically-reasonable nH for nearby young stars\n",
    "\n",
    "notebook_plotter(test_model_2, log_axis = 'ylog', autoscale = 'y', figsize_y = 3, plot_type = 'data_and_convolved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note, that the actual values used to simulate the dataset are ma2.nH = 0.1 atoms/cm2 , p2.kT = 2.0 keV , and p2.norm = 1E-3. Also note that sherpa includes the guess() function for estimating parameter ranges given a loaded dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets fit() the data and overplot the best-fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets fit the model to the loaded dataset and inspect the data+fit\n",
    "fit()\n",
    "\n",
    "plot_fit()\n",
    "plot_model(overplot=True)\n",
    "\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's re-run notebook_plotter(). We will see that the model parameters in sherpa have been set to the values determined in the fit. Note that previous jupyter notebook cells running notebook_plotter() will **not** be updated with these best-fit parameter values. It is not recommend to run notebook_plotter() in multiple cells if you intend to be careful about setting model parameters (like you would right before a fit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_plotter(test_model_2, log_axis = 'ylog', autoscale = 'y', figsize_y = 3, plot_type = 'data_and_convolved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also use the notebook_plotter to view the contribution of the model to the convolved spectrum. Try adjusting the parameters to see how they affect the spectrum. While we can access this plot using the previous cell's plot by selecting 'both_models' from the plot_type window, it makes more sense for a tutorial like this to re-plot.\n",
    "\n",
    "#### NOTE: Adjusting model parameters in this cell will update the source model parameters in sherpa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_plotter(test_model_2, log_axis = 'ylog', figsize_y = 3, plot_type = 'both_models', autoscale = 'none', ylim_low = '1E-8', ylim_high = '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also view this dataset in wavelength space with the set_analysis() command. Keep in mind this will set the analysis to 'wavelength' for the entire sherpa session or untill you switch back using set_analysis('energy')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also see what this spectra looks like in wavelength space by using set_analysis()\n",
    "set_analysis('wavelength')\n",
    "\n",
    "notebook_plotter(test_model_2, log_axis = 'ylog', figsize_y = 3, plot_type = 'both_models', autoscale = 'none', ylim_low = 1E-15, ylim_high = 10, xlim_low = 0, xlim_high = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXAMPLE 3 - Simulating a spectrum for a proposal with help from notebook_plotter()**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Let's say we're interested in identifying a sample of young, pre-main sequence stars whose spectrum may include a 6.4 keV emission feature characteristic of neutral iron fluoresence emission from cold circumstellar disk gas irradiated by coronal X-rays. It would help to first look at spectral models typically used to fit young stellar X-ray spectra to determine what characteristics of the spectrum are important for detecting an emission line at 6.4 keV.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We're going to use sherpa's fake_pha() command to simulate a spectrum but first we will need to choose a model. Let's go with a simple plasma model typically used to fit spectra of young stars. For the moment, we will choose a model that does **not** include the emission line of interest at 6.4 keV because most stars don't show this feature. We will add that in later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean() #lets run clean() to remove the datasets of previous examples from our sherpa session.\n",
    "test_model_3 = xstbabs.ma3 * (xsapec.p3)\n",
    "\n",
    "#lets set some parameters typical of young stellar coronae\n",
    "ma3.nH = 0.1\n",
    "p3.kT = 1.3\n",
    "p3.Abundanc = 0.5\n",
    "p3.norm = 3E-3\n",
    "test_model_3\n",
    "\n",
    "#lets display the model parameters that were set\n",
    "test_model_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To fake a spectrum for a future proposal, we will need to use chandra responses (ARF AND RMF) relevant for the year of our proposed observations and for our instrument of choice. For this case, we will use the same responses in example 2 which are for Cycle 26 and can be found here: https://cxc.cfa.harvard.edu/caldb/prop_plan/imaging/. Please note that these responses are only meant to be used for simulating spectra and should not be used to analyze real Chandra observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "#download the ACIS-S ARF\n",
    "url_arf = ('https://cxc.cfa.harvard.edu/caldb/prop_plan/imaging/CY26/aciss_aimpt_cy26.arf')\n",
    "filename_arf = 'aciss_aimpt_cy26.arf'\n",
    "urlretrieve(url_arf, filename_arf)\n",
    "\n",
    "#download the ACIS-S RMF\n",
    "url_rmf = ('https://cxc.cfa.harvard.edu/caldb/prop_plan/imaging/CY26/aciss_aimpt_cy26.rmf')\n",
    "filename_rmf = 'aciss_aimpt_cy26.rmf'\n",
    "urlretrieve(url_rmf, filename_rmf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets use fake_pha() to simulate a typical young stellar coronal source in a 100 ks observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_source(test_model_3)\n",
    "\n",
    "exposure_time = 100E3 # 100 ks\n",
    "\n",
    "fake_pha(1, arf=filename_arf, rmf=filename_rmf, exposure = exposure_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can group the spectrum and ignore everthing but 0.5-8.0 keV counts and display the faked data with the convolved model using the sherpa command plot_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts(1,7)\n",
    "notice()\n",
    "ignore(0,0.5)\n",
    "ignore(8,)\n",
    "plot_data()\n",
    "plt.yscale('log')\n",
    "plot_model(overplot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets notebook_plotter() to inspect the simulated (faked) spectrum and its underlying model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma3.nH.min = 0.01\n",
    "ma3.nH.max = 30\n",
    "p3.kT.min = 0.2\n",
    "p3.kT.max = 9\n",
    "\n",
    "notebook_plotter(test_model_3, log_axis = 'ylog', autoscale = 'none',  plot_type = 'data_and_convolved_model', xlim_low = 0.3, xlim_high = 8.0, ylim_low = 1E-7, ylim_high = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *We can see that there are not many counts in the spectrum >~ 5 keV which is going to make it difficult to detect any specific emission features in this part of the spectrum. What happens if you take the p3.kT widget slider and increase the plasma temperature? You'll notice that the convolved model (orange) quickly rises about the dataset indicating that, given the same normalization, hot plasma emits more X-rays at higher energies. Lets take a closer look at the underlying plasma model in the next cell.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3.kT = 1.3 #just in case you changed the value of p3.kT in the interactive widget, lets set it back to 1.3 keV for the purposes of this notebook.\n",
    "\n",
    "notebook_plotter(test_model_3, log_axis = 'ylog', autoscale = 'none',  plot_type = 'both_models', xlim_low = 0.3, xlim_high = 8.0, ylim_low = 1E-7, ylim_high = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Here we see the underlying plasma model (red) used to simulate the spectrum and the same model convolved with the chandra ACIS-S responses (orange). For emission line sources like young, pre-main sequence stars, the shape of the spectrum in low resolution spectra (i.e., CCD imaging-resolution) is driven in large part by all the underlying emission lines.*\n",
    "\n",
    "#### *Try changing the plasma temperature parameter in this interactive model and note how the shape of the convolved model changes. As you increase plasma temperature, emission lines at higher energies increase in strength relative to those at energies <~ 1 keV pushing up the high enery portion of the spectrum. Of note, is the very bright series of lines at 6.7 keV assocaited with with iron (Fe XXV). This 6.7 keV feature has been identified in the spectra of many hot stars and is typically used to demonstrate that the underyling plasma is indeed hot. You can see how if you reduce the plasma temperature, this 6.7 keV emission feature is reduced.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, lets take a look at this simulated spectrum but with a model that includes a 6.4 keV gaussian line meant to represent Fe flourescence emission. We will set all the other parameters initially to the same values as our simulated spectrum but this time adding in a 6.4 keV gaussian component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, lets take at this simulated spectrum but with a model that includes a 6.4 gaussian line meant to represent Fe flourescent emission. We will set all the other parameters initially to the same values as are simulated spectrum but this time add in the gaussian component.\n",
    "\n",
    "#You can now see the presence of a gaussian line at 6.4 keV in the unconvolved model (red) and its contribution to the convolved model (orange). Try increasing the g4.norm parameter to see how an increase in line flux affects the spectrum. Given the current model parameters, it appears you'll need a g4.norm value >~ 1E-8 in order to identify any feature. \n",
    "\n",
    "test_model_4 = xstbabs.ma4 * (xsapec.p4 + xsgaussian.g4)\n",
    "\n",
    "ma4.nH = 0.1\n",
    "p4.kT = 1.3\n",
    "#p4.kT = 3.0\n",
    "p4.Abundanc = 0.5\n",
    "p4.norm = 3E-3\n",
    "g4.sigma = 0.0\n",
    "g4.norm = 5E-7\n",
    "g4.LineE = 6.4\n",
    "\n",
    "ma4.nH.min = 0.01\n",
    "ma4.nH.max = 30\n",
    "p4.kT.min = 0.3\n",
    "p4.kT.max = 5\n",
    "\n",
    "g4.LineE.min = 6.39\n",
    "g4.LineE.max = 6.41\n",
    "g4.norm.max = 1E-2\n",
    "g4.sigma.max = 0.05\n",
    "\n",
    "set_source(test_model_4)\n",
    "\n",
    "notebook_plotter(test_model_4, log_axis = 'ylog', autoscale = 'none',  plot_type = 'both_models', xlim_low = 0.3, xlim_high = 8.0, ylim_low = 1E-7, ylim_high = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### *You can now see the presence of a gaussian line at 6.4 keV in the unconvolved model (red) and its contribution to the convolved model (orange). Try increasing the g4.norm parameter by entering a higher value in the widget box to see how an increase in line flux affects the spectrum. Given the current model parameters, it appears you'll need a g4.norm value >~ 1E-8 in order to identify any feature. If you wish to zoom-in on this line, you can set the xlim_low and xlim_high values in the plotting options.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets look at our new convolved model with the previous faked spectrum which does not include a 6.4 keV component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will reset the model values in case they were modified too drastically in the previous notebook_plotter() cell.\n",
    "ma4.nH = 0.1\n",
    "p4.kT = 1.3\n",
    "p4.Abundanc = 0.5\n",
    "p4.norm = 3E-3\n",
    "g4.sigma = 0.0\n",
    "g4.norm = 5E-7\n",
    "g4.LineE = 6.4\n",
    "\n",
    "notebook_plotter(test_model_4, log_axis = 'ylog', autoscale = 'none',  plot_type = 'data_and_convolved_model', xlim_low = 0.3, xlim_high = 8.0, ylim_low = 1E-7, ylim_high = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Here we can see the 6.4 emission line component in the convolved model but there are relatively few counts in this spectrum >~ 5 keV which will make it difficult to detect without significantly more exposure time. We saw in a previous cell that increasing the plasma temperature will increase the number of counts at higher energies for a set normalization. Try increasing the value of p4.kT to be 3.0 keV. Compared to the previous simulation, this new, (hotter) model has a lot more flux > 5 keV although we now have to increase the value of g4.norm to ~3E-6 so it is visible above the continuum of the spectrum.*\n",
    "\n",
    "#### *Since this science case is focused on detecting a 6.4 keV feature, it will be easier to detect such a feature with Chandra by focusing on young stars that already exhibit hot plasma (e.g., >~ 3 keV) as there will be more counts in the region where we expect this feature.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So now lets try simulating a spectrum with this gaussian component at 6.4 keV and the above model parameters. While you should be able to run fake_pha() using the model values set in the previous cell's notebook_plotter(), its safer to just reset the values here before simulating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so now lets try simulating a spectrum with this gaussian component at 6.4 keV and the above model parameters. While you should be able to run fake_pha() using the model values set in the previous cell's notebook_plotter(), its safer to just reset the values here before simulating.\n",
    "\n",
    "ma4.nH = 0.1\n",
    "p4.kT = 3.0\n",
    "p4.Abundanc = 0.5\n",
    "p4.norm = 3E-3\n",
    "g4.sigma = 0.0\n",
    "g4.norm = 3E-6\n",
    "g4.LineE = 6.4\n",
    "\n",
    "set_source(test_model_4)\n",
    "\n",
    "exposure_time = 100E3 #ks\n",
    "\n",
    "fake_pha(1, arf=filename_arf, rmf=filename_rmf, exposure = exposure_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Like before, lets group the spectrum and ignore everthing but 0.5-8.0 keV and display the faked data with the convolved model using the sherpa plot_data() and plot_model() commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can group the spectrum and ignore everthing but 0.5-8.0 keV and display the faked data with the convolved model using sherpa commands\n",
    "group_counts(1,10)\n",
    "notice()\n",
    "ignore(0,0.5)\n",
    "ignore(8,)\n",
    "plot_data()\n",
    "plt.yscale('log')\n",
    "plot_model(overplot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this simulated spectrum, we can now identify both the 6.4 and 6.7 keV emission lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_plotter(test_model_4, log_axis = 'ylog', autoscale = 'none',  plot_type = 'data_and_convolved_model', xlim_low = 0.3, xlim_high = 8.0, ylim_low = 1E-7, ylim_high = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have a simulation of a source where we can detect these lines, a next and final step (left to the reader) would be to explore the parameter space for this model and simulation. If proposing to observe a real source, you'll want to simulate spectra using values appropraite for the real object (e.g., flux, plasma temperature, median energy, nH). After modifying the relevant parameters in the model, you can re-simulate a spectrum for each source to determine the best instrument setup and exposure time request. The 6.4 keV emission feature discussed in this example is rare and is limited to young stars hosting circumstellar disks with reservoirs of neutral Fe. \n",
    "\n",
    "#### A helpful tool in determing what normalization parameter you can use for your simualtion is the sherpa command calc_energy_flux(). This allows you to evaluate your loaded model with an energy range to determine the flux. If you'd like to simulate a real source's spectrum, be sure to match the simulation's flux with your source of interest's flux (via the plasma normalization in this case)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a17b56303b07176fb2bb59278b3e4b13878287cc672133da207aa44c7ef3e23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
